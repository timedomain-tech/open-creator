\section{Introduction}
AI agents engage in complex reasoning by integrating planning ~\cite{wei2022chain, xu2023rewoo, wang2023selfconsistency, yao2023tree}, decision-making, and the utilization of appropriate tools or APIs ~\cite{schick2023toolformer, li2023apibank}. However, these tools are typically predetermined and designed by humans, and the number of available tools is often limited due to the constraints on the input context length of Large Language Models (LLMs). To enhance the versatility of AI agents, a viable approach is to amalgamate the code-generation capabilities of LLMs with code execution functionalities. This integration allows for the flexible writing and execution of code to address specific user needs, embodying the role of Code Interpreters ~\cite{openinterpreter}.

Given that LLMs occasionally generate erroneous codes—leading to low robustness and inability to meet user requirements—recent research has focused on enabling LLMs to auto-correct codes through environmental feedback ~\cite{skreta2023errors, yao2022react, wang2023voyager, song2023llmplanner}. Additionally, there is emphasis on developing sophisticated projects through rational task decomposition and persistent memory. This focus has given rise to a plethora of AI agent frameworks, including MetaGPT ~\cite{hong2023metagpt}, ChatDev ~\cite{qian2023communicative}, GPT-enginger ~\cite{GPTEngineer}, GPT-term ~\cite{GPTeam}, and codeplan ~\cite{bairi2023codeplan}. These studies explore collaborative mechanisms among different roles, introduction of improved environments, enhanced feedback from agents, optimized task decomposition, and various engineering tricks, collectively contributing to the flourishing ecosystem of AI agents in the fields of Computer Science and Software Engineering. A comprehensive literature review in this area has been conducted by Wang et al ~\cite{wang2023survey}.
